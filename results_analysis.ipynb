{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference (NLI) Results and Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will load a pretrained NLI model, demonstrate its usage on custom examples, present an overview of the results, and perform error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLIClassifier(\n",
       "  (encoder): LSTMEncoder(\n",
       "    (enc_lstm): LSTM(300, 2048)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import models\n",
    "\n",
    "config_nli_model = {\n",
    "    'n_words'        :  37927         ,\n",
    "    'word_emb_dim'   :  300   ,\n",
    "    'enc_lstm_dim'   :  2048   ,\n",
    "    'dpout_model'    :  0.0    ,\n",
    "    'fc_dim'         :  512         ,\n",
    "    'bsize'          :  16     ,\n",
    "    'n_classes'      :  3      ,\n",
    "    'encoder_type'   :  'LSTMEncoder'   ,\n",
    "    'use_cuda'       :  True                  ,\n",
    "    }\n",
    "\n",
    "model_path = \"savedir/lstm_model.pickle\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Create a model instance and load the state dictionary\n",
    "model_instance = models.NLIClassifier(config_nli_model)  # Assuming the LSTMEncoder is imported from models module\n",
    "model_instance.load_state_dict(state_dict)\n",
    "model_instance.to(device)\n",
    "model_instance.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Model Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import NLIDataset, build_vocab, get_nli, collate_fn\n",
    "import numpy as np\n",
    "\n",
    "LABELS = ['entailment', 'neutral', 'contradiction']\n",
    "\n",
    "def predict_entailment(model, premise, hypothesis):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_path = \"data/\"\n",
    "    glove_path = \"glove/glove.840B.300d.txt\"\n",
    "\n",
    "    train_data, valid_data, test_data = get_nli(data_path)\n",
    "    word_vec = build_vocab(train_data['s1'] + train_data['s2'], glove_path)\n",
    "    dataset = NLIDataset(train_data, word_vec)\n",
    "\n",
    "    s1_idx, s1_length = dataset._get_sentence_indices(premise)\n",
    "    s2_idx, s2_length = dataset._get_sentence_indices(hypothesis)\n",
    "    s1_tensor, s1_length = s1_idx.unsqueeze(0).to(device), torch.tensor([s1_length]).to(\"cpu\")\n",
    "    s2_tensor, s2_length = s2_idx.unsqueeze(0).to(device), torch.tensor([s2_length]).to(\"cpu\")\n",
    "    s1 = (s1_tensor, s1_length)\n",
    "    s2 = (s2_tensor, s2_length)\n",
    "\n",
    "    logits = model(s1, s2)\n",
    "    prediction = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37325/62999 words with glove vectors\n",
      "Vocab size : 37325\n",
      "Prediction: entailment\n"
     ]
    }
   ],
   "source": [
    "premise = \"Two men sitting in the sun\"\n",
    "hypothesis = \"Nobody is sitting in the shade\"\n",
    "\n",
    "prediction = predict_entailment(model_instance, premise, hypothesis)\n",
    "print(\"Prediction:\", LABELS[prediction[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
