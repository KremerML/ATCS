{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference (NLI) Results and Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                   | SNLI Test Accuracy |\n",
    "|-------------------------|--------------------|\n",
    "| Basic Encoder           | 61.93              |\n",
    "| LSTM                    | 77.64              |\n",
    "| BiLSTM                  | 76.81              |\n",
    "| BiLSTM with Max Pooling | 80.2               |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will load the best performing pretrained NLI model (biLSTM with max pooling), demonstrate its usage on custom examples, present an overview of the results, and perform error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLIClassifier(\n",
       "  (encoder): biLSTMMaxPoolEncoder(\n",
       "    (enc_lstm): LSTM(300, 2048, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import models\n",
    "\n",
    "config_nli_model = {\n",
    "    'n_words'        :  37927         ,\n",
    "    'word_emb_dim'   :  300   ,\n",
    "    'enc_lstm_dim'   :  2048   ,\n",
    "    'dpout_model'    :  0.0    ,\n",
    "    'fc_dim'         :  512         ,\n",
    "    'bsize'          :  16     ,\n",
    "    'n_classes'      :  3      ,\n",
    "    'encoder_type'   :  'biLSTMMaxPoolEncoder'   ,\n",
    "    'use_cuda'       :  True                  ,\n",
    "    }\n",
    "\n",
    "model_path = \"savedir/maxpool_bilstm_model.pickle\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Create a model instance and load the state dictionary\n",
    "model_instance = models.NLIClassifier(config_nli_model)  # Assuming the LSTMEncoder is imported from models module\n",
    "model_instance.load_state_dict(state_dict)\n",
    "model_instance.to(device)\n",
    "model_instance.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Model Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import NLIDataset, build_vocab, get_nli, collate_fn\n",
    "import numpy as np\n",
    "\n",
    "LABELS = ['entailment', 'neutral', 'contradiction']\n",
    "\n",
    "def predict_entailment(model, premise, hypothesis):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_path = \"data/\"\n",
    "    glove_path = \"glove/glove.840B.300d.txt\"\n",
    "\n",
    "    train_data, valid_data, test_data = get_nli(data_path)\n",
    "    word_vec = build_vocab(train_data['s1'] + train_data['s2'], glove_path)\n",
    "    dataset = NLIDataset(train_data, word_vec)\n",
    "\n",
    "    s1_idx, s1_length = dataset._get_sentence_indices(premise)\n",
    "    s2_idx, s2_length = dataset._get_sentence_indices(hypothesis)\n",
    "    s1_tensor, s1_length = s1_idx.unsqueeze(0).to(device), torch.tensor([s1_length]).to(\"cpu\")\n",
    "    s2_tensor, s2_length = s2_idx.unsqueeze(0).to(device), torch.tensor([s2_length]).to(\"cpu\")\n",
    "    s1 = (s1_tensor, s1_length)\n",
    "    s2 = (s2_tensor, s2_length)\n",
    "\n",
    "    logits = model(s1, s2)\n",
    "    prediction = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37325/62999 words with glove vectors\n",
      "Vocab size : 37325\n",
      "Prediction: contradiction\n"
     ]
    }
   ],
   "source": [
    "premise = \"Two men sitting in the sun\"\n",
    "hypothesis = \"Nobody is sitting in the shade\"\n",
    "\n",
    "prediction = predict_entailment(model_instance, premise, hypothesis)\n",
    "print(\"Prediction:\", LABELS[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37325/62999 words with glove vectors\n",
      "Vocab size : 37325\n",
      "Prediction: contradiction\n"
     ]
    }
   ],
   "source": [
    "premise = \"A man is walking a dog\"\n",
    "hypothesis = \"No cat is outside\"\n",
    "\n",
    "prediction = predict_entailment(model_instance, premise, hypothesis)\n",
    "print(\"Prediction:\", LABELS[prediction[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between the premise and the hypothesis is subtle and nuanced, so there are a few reasons why it could be difficult for the model to make the correct inference:\n",
    "1. First of all, there is a complete vocab mismatch. There is no direct overlap between the words in the premise and the hypothesis, except for \"sitting.\" The model needs to understand the relationship between \"sun\" and \"shade,\" which are antonyms, but not explicitly mentioned in the same sentence.\n",
    "2. The correct entailment relies on understanding that although sitting in the sun implies that the two men are not in the shade, the two sentences are not related. The model might not be able to make this inference because this information is not explicitly stated in the premise.\n",
    "3. The hypothesis is quite ambiguous. Stating that \"nobody is sitting in the shade\" makes it unclear whether it refers to the two men or everybody in the world.\n",
    "\n",
    "For the second example with the dog and cat, the model predicts that their entailment is contradiction. This is because the model is not able to understand that the two sentences are not related. The model is able to make an incorrect inference because the words \"dog\" and \"cat\" are in the premise and hypothesis, and the model understands this as a contradiction. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
